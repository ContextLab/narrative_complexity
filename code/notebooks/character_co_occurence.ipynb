{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the file that feature extractor notebook generates for each script\n",
    "#out_fn = '/Users/vassiki/Desktop/narrative_complexity/code/notebooks/annotations_with_char_embeddings.csv'\n",
    "out_fn = '/Users/vassiki/Desktop/narrative_complexity/code/notebooks/annotations.csv'\n",
    "out_df = pd.read_csv(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chars_from_df(out_df):   \n",
    "    \"\"\"\n",
    "    Function to clean up unique list of characters, will be redundant after\n",
    "    the feature extraction notebook is updated\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    out_df: output csv for each script with segmented events as rows\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    characters: 2d list of unique characters in each event\n",
    "    \"\"\"\n",
    "    characters = []\n",
    "    for row in range(out_df.shape[0]):\n",
    "    \n",
    "        character_per_event = eval(out_df.loc[row, 'characters'])\n",
    "        unique_chars_events = character_per_event.keys()\n",
    "        chars_ev = [' '.join(c.split()) for c in list(unique_chars_events)]\n",
    "        first_name = [c.split(' ')[0] for c in chars_ev]\n",
    "        unique_first = list(dict.fromkeys(first_name))\n",
    "        # pos tag\n",
    "        #pos_tag_names = nltk.pos_tag(unique_first)\n",
    "        #noun_names = [n[0] for n in pos_tag_names if 'VB' not in n[1]]\n",
    "\n",
    "        characters.append(unique_first)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooccurence_matrix_one_event(characters, event_num=0):\n",
    "    \"\"\"\n",
    "    Function to create cooccurence matrix for all characters in an event.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    characters: 2d list of unique characters in each event\n",
    "    event_num: default 0, row number of event to return cooccurence matrix for\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    co_occurence_df: unique char by unique char dataframe with tallies\n",
    "                        for character cooccurences\n",
    "    \"\"\"\n",
    "    chars = list(dict.fromkeys(sum(characters,[])))\n",
    "    total_array_size = len(chars)\n",
    "    co_occurence_array = np.zeros((total_array_size, total_array_size))\n",
    "    co_occurence_df = pd.DataFrame(co_occurence_array, columns = chars, index=chars)\n",
    "    #all_pairs = list(itertools.combinations(characters[event_num], 2))\n",
    "    all_pairs = list(itertools.permutations(characters[event_num], 2))\n",
    "    for pair in all_pairs:\n",
    "        co_occurence_df.loc[pair[0], pair[1]] += 1\n",
    "    return co_occurence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooccurence_matrix_all_events(characters):\n",
    "    \"\"\"\n",
    "    Function to create cooccurence matrix across all events\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    characters: 2d list of unique characters in each event\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    co_occurence_df: character by character cooccurence matrix across\n",
    "                        all events\n",
    "    \"\"\"\n",
    "    chars = list(dict.fromkeys(sum(characters,[])))\n",
    "    total_array_size = len(chars)\n",
    "    co_occurence_array = np.zeros((total_array_size, total_array_size))\n",
    "    co_occurence_df = pd.DataFrame(co_occurence_array, columns = chars, index=chars)\n",
    "    for event_chars in range(len(characters)):\n",
    "        #all_pairs = list(itertools.combinations(characters[event_chars], 2))\n",
    "        all_pairs = list(itertools.permutations(characters[event_chars], 2))\n",
    "        for pair in all_pairs:\n",
    "            co_occurence_df.loc[pair[0], pair[1]] += 1\n",
    "    return co_occurence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_event_cooccurence(fn, chars, num=0):\n",
    "    \"\"\"\n",
    "    Function to plot each event's cooccurence matrix\n",
    "    \n",
    "    Parameters:\n",
    "    fn: filename to save the co-occurence plot with\n",
    "    chars: 2d list of unique characters in each event \n",
    "    num: default 0, event number\n",
    "    \"\"\"\n",
    "    cdf  = get_cooccurence_matrix_one_event(chars, num)\n",
    "    l = list(cdf.columns)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(cdf, xticklabels=l, yticklabels=l)\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_events_cooccurence(fn, chars):\n",
    "    \"\"\"\n",
    "    Function to plot cooccurence matrix across all events\n",
    "    \n",
    "    Parameters:\n",
    "    fn: filename to save the co-occurence plot with\n",
    "    chars: 2d list of unique characters in each event\n",
    "    \"\"\"    \n",
    "    cca = get_cooccurence_matrix_all_events(chars)\n",
    "    labels = list(cca.columns)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(cca, xticklabels=labels, yticklabels=labels)\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plot for all events\n",
    "characters = get_chars_from_df(out_df)\n",
    "root_dir = '/Users/vassiki/Desktop/narrative_complexity/notebooks/figures/'\n",
    "fn = os.path.join(root_dir, 'character_occurence.png')\n",
    "plot_all_events_cooccurence(fn, characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plot for one event at a time\n",
    "characters = get_chars_from_df(out_df)\n",
    "root_dir = '/Users/vassiki/Desktop/narrative_complexity/notebooks/figures/'\n",
    "for event_num in range(len(characters)):\n",
    "    fn = os.path.join(root_dir, 'character_occurence_event_{0}.png'.format(event_num))\n",
    "    plot_one_event_cooccurence(fn, characters, event_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `convert -delay 10 -loop 0 *event*.png cooccurence.gif` in bash to generate gif from all events from the figures subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example\n",
    "all_elements = np.arange(10)\n",
    "elements_in_events = []\n",
    "num_events = 20\n",
    "for ev in range(num_events):\n",
    "    elems_this_event = np.random.choice(5, np.random.randint(1,5, size=1), replace=False)\n",
    "    elements_in_events.append(list(elems_this_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cdf = get_cooccurence_matrix_all_events(elements_in_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = all_cdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_check_symmetric(a, tol=1e-8):\n",
    "    return np.all(np.abs(a-a.T) < tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_symmetric(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired my Mark's talk, implementing Correspondence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/elena-sharova/correspondence_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = get_chars_from_df(out_df)\n",
    "count_df = get_cooccurence_matrix_all_events(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = count_df.gt(10)\n",
    "at= count_df.loc[m.any(axis=1), m.any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleCrosstab = at.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grandTotal = np.sum(sampleCrosstab)\n",
    "correspondenceMatrix = np.divide(sampleCrosstab,grandTotal)\n",
    "rowTotals = np.sum(correspondenceMatrix, axis=1)\n",
    "columnTotals = np.sum(correspondenceMatrix, axis=0)\n",
    "independenceModel = np.outer(rowTotals, columnTotals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiSquaredStatistic = grandTotal*np.sum(np.square(correspondenceMatrix-independenceModel)/independenceModel)\n",
    "print(chiSquaredStatistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check - compare to scipy Chi-Squared test\n",
    "from scipy.stats import chi2_contingency\n",
    "statistic, prob, dof, ex = chi2_contingency(sampleCrosstab)\n",
    "print(statistic)\n",
    "print(np.round(prob, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correspondence_analysis(sampleCrosstab):\n",
    "    grandTotal = np.sum(sampleCrosstab)\n",
    "    correspondenceMatrix = np.divide(sampleCrosstab,grandTotal)\n",
    "    rowTotals = np.sum(correspondenceMatrix, axis=1)\n",
    "    columnTotals = np.sum(correspondenceMatrix, axis=0)\n",
    "    independenceModel = np.outer(rowTotals, columnTotals)\n",
    "    chiSquaredStatistic = grandTotal*np.sum(np.square(correspondenceMatrix-independenceModel)/independenceModel)\n",
    "    print('Chi Squared for this matrix is {0}'.format(chiSquaredStatistic))\n",
    "    # pre-calculate normalised rows\n",
    "    norm_correspondenceMatrix = np.divide(correspondenceMatrix,rowTotals[:, None])\n",
    "\n",
    "    chiSquaredDistances = np.zeros((correspondenceMatrix.shape[0],correspondenceMatrix.shape[0]))\n",
    "\n",
    "    norm_columnTotals = np.sum(norm_correspondenceMatrix, axis=0)\n",
    "    for row in range(correspondenceMatrix.shape[0]):\n",
    "        chiSquaredDistances[row]=np.sqrt(np.sum(np.square(norm_correspondenceMatrix\n",
    "                                                        -norm_correspondenceMatrix[row])/columnTotals, axis=1))\n",
    "\n",
    "\n",
    "    standardizedResiduals = np.divide((correspondenceMatrix-independenceModel),np.sqrt(independenceModel))\n",
    "\n",
    "    u,s,vh = np.linalg.svd(standardizedResiduals, full_matrices=False)\n",
    "\n",
    "    deltaR = np.diag(np.divide(1.0,np.sqrt(rowTotals)))\n",
    "\n",
    "    rowScores=np.dot(np.dot(deltaR,u),np.diag(s))\n",
    "    return rowScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowScores = correspondence_analysis(sampleCrosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFirstTwoComponents = pd.DataFrame(data=[l[0:2] for l in rowScores], columns=['X', 'Y'], index=at.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data=dfFirstTwoComponents,x='X', y='Y', hue=at.columns)\n",
    "ax.axhline(y=0, color='k')\n",
    "ax.axvline(x=0, color='k')\n",
    "ax.get_legend().set_visible(False)\n",
    "\n",
    "for label in at.columns:\n",
    "    plt.annotate(label, \n",
    "                 (dfFirstTwoComponents.loc[label,:]['X'],\n",
    "                  dfFirstTwoComponents.loc[label,:]['Y']),\n",
    "                 horizontalalignment='center', verticalalignment='center',size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFirstTwoComponents['group'] = list(dfFirstTwoComponents.index)\n",
    "dfFirstTwoComponents['colors'] = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "#plt.figure(figsize = (12,8))\n",
    "ax = sns.scatterplot(dfFirstTwoComponents['X'], dfFirstTwoComponents['Y'])\n",
    "\n",
    "for line in range(0,dfFirstTwoComponents.shape[0]):\n",
    "     ax.text(dfFirstTwoComponents.X[line], dfFirstTwoComponents.Y[line], dfFirstTwoComponents.group[line], horizontalalignment='center', size='large', color= dfFirstTwoComponents.colors[line])\n",
    "        \n",
    "fig.savefig('character2d.png', bbox_inches=\"tight\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('characters_2d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character co-occurrence matrix weighted by number of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chars_from_df(out_df):   \n",
    "    \"\"\"\n",
    "    Function to clean up unique list of characters, will be redundant after\n",
    "    the feature extraction notebook is updated\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    out_df: output csv for each script with segmented events as rows\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    characters: 2d list of unique characters in each event\n",
    "    \"\"\"\n",
    "    characters = []\n",
    "    for row in range(out_df.shape[0]):\n",
    "    \n",
    "        character_per_event = eval(out_df.loc[row, 'characters'])\n",
    "        vals = {key: character_per_event[key] for key in character_per_event}\n",
    "        characters.append(vals)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_by_char_all_events(out_df):\n",
    "    char_event_dict = get_chars_from_df(out_df)\n",
    "    row_length = out_df.shape[0]\n",
    "    c = [list(val.keys()) for val in char_event_dict]\n",
    "    chars = list(dict.fromkeys(sum(c,[])))\n",
    "    col_length = len(chars)\n",
    "    print('We have {0} events and {1} characters'.format(row_length, col_length))\n",
    "    row_names = ['Event {0}'.format(n) for n in np.arange(row_length)]\n",
    "    col_names = chars\n",
    "    df = pd.DataFrame(np.zeros((row_length, col_length)), columns=col_names, index=row_names)\n",
    "    \n",
    "    for event_num in range(row_length):\n",
    "        for char_k, val in char_event_dict[event_num].items():\n",
    "            row_label = 'Event {}'.format(event_num)\n",
    "            df.loc[row_label, char_k] += val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_by_char_one_event(out_df, event_num=0):\n",
    "    char_event_dict = get_chars_from_df(out_df)\n",
    "    row_length = out_df.shape[0]\n",
    "    c = [list(val.keys()) for val in char_event_dict]\n",
    "    chars = list(dict.fromkeys(sum(c,[])))\n",
    "    col_length = len(chars)\n",
    "    row_names = ['Event {0}'.format(n) for n in np.arange(row_length)]\n",
    "    col_names = chars\n",
    "    edf = pd.DataFrame(np.zeros((row_length, col_length)), columns=col_names, index=row_names)\n",
    "    \n",
    "    for char_k, val in char_event_dict[event_num].items():\n",
    "        row_label = 'Event {}'.format(event_num)\n",
    "        edf.loc[row_label, char_k] += val\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_event(fn, df, event_num=0):\n",
    "    edf = event_by_char_one_event(df, event_num)\n",
    "    xl = list(edf.columns)\n",
    "    yl = list(edf.index)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(edf, xticklabels=xl, yticklabels=yl, cmap=\"BuGn_r\", cbar=False)\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_events(fn, df):\n",
    "    df = event_by_char_all_events(df)\n",
    "    xl = list(df.columns)\n",
    "    yl = list(df.index)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(df, xticklabels=xl, yticklabels=yl, cmap=\"BuGn_r\")\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save all the pngs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = '../../figures/'\n",
    "movie_name = 'ten_things'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_num in range(out_df.shape[0]):\n",
    "    fn = os.path.join(fig_dir, '{0}_event_{1}.png'.format(movie_name, \"{:02d}\".format(event_num)))\n",
    "    plot_one_event(fn, out_df, event_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(fig_dir, '{}_all_events.png'.format(movie_name))\n",
    "plot_all_events(fn, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using timecorr for plotting dynamic correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timecorr as tc\n",
    "\n",
    "def get_dynamic_correlations(out_df):\n",
    "\n",
    "    df = event_by_char_all_events(out_df)\n",
    "\n",
    "    mention_matrix = df.values\n",
    "    print('Original matrix has dimensions'.format(mention_matrix.shape))\n",
    "\n",
    "    # specify kernel\n",
    "    width = 3\n",
    "    gaussian = {'name': 'Gaussian', 'weights': tc.gaussian_weights, 'params': {'var': width}}\n",
    "    vec_corrs = tc.timecorr(mention_matrix, weights_function=gaussian['weights'], weights_params=gaussian['params'])\n",
    "\n",
    "    print('vectorized shape : ' + str(np.shape(vec_corrs)))\n",
    "\n",
    "    # use the vec2mat function to convert vectorized correlations to moment-by-moment full correlations\n",
    "    mat_corrs = tc.vec2mat(vec_corrs)\n",
    "\n",
    "    print('matrix shape : ' + str(np.shape(mat_corrs)))\n",
    "    \n",
    "    return mat_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyna_mat = get_dynamic_correlations(out_df)\n",
    "df = event_by_char_all_events(out_df)\n",
    "char_names = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = '../../figures/'\n",
    "movie_name = 'ten_things'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dyna_mats(out_df, filepath, movie_name):\n",
    "    dyna_mat = get_dynamic_correlations(out_df)\n",
    "    df = event_by_char_all_events(out_df)\n",
    "    char_names = df.columns\n",
    "    for tp in range(dyna_mat.shape[2]):\n",
    "        plt.figure(figsize=(20,15))\n",
    "        sns.set(font_scale = 0.8)\n",
    "        sns.heatmap(mat_corrs[:, :, tp], xticklabels=char_names, yticklabels=char_names, cmap=\"RdBu_r\")\n",
    "        fn = os.path.join(filepath, '{0}_dyna_mat_event_{1}'.format(movie_name, \"{:02d}\".format(tp)))\n",
    "        plt.savefig(fn, bbox_inches = \"tight\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dyna_mats(out_df, fig_dir, movie_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
